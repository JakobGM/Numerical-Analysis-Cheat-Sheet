\section{ODEs}
% Should I add Leipshitz definiton?
Solving the initial value problem
$$
\begin{cases}
y' = f(t,y) \\
y(a) = y_a \\
t in [a,b]
\end{cases}
$$
with...
\subsubsection{Euler's method}
% At the very least, backward/forward Euler.
\begin{align*}
w_0 = & y_0 \\
w_{i+1} = & w_{i} + h f(t_i, w_i)
\end{align*}

\subsubsection{Backwards Euler Method}
Use when the diff. equation is \textbf{stiff}, i.e. attracting solutions are surrounded with fast-changing nearby solutions, the linear part of $y$ on the r.h.s.is large and negative.
\begin{align*}
w_0 = &y_0 \\
w_{i+1} = & w_{i} + h f(t_i, w_{i+1})
\end{align*}
Solving this implicit equation for $w_{i+1}$ might require the use of Newton's method.
 
\subsubsection{Explicit Trapezoid Method}
%Trapezoid method can also be easily stated if you remember the trapezoid quadrature/explicit Euler. 
\begin{align*}
w_0 &= y_0 \\
w_{i+1} &= w_i h \frac{h}{2}(f(t_i,w_i)) + f(t_i + h, w_i + hf(t_i,w_i)))
\end{align*}

\subsubsection{Local and global error}
%Concepts of local/global errors and how local truncation error can be derived for a given method using a Taylor series expansion. 
\begin{definition}
A function $f(t,y)$ is \textbf{Lipschitz continuous} in the variable $y$ on the rectangle $S = [a,b] \times [\alpha, \beta]$ if there exists a constant $L$ (called the \textbf{Lipschitz constant}) satisfying
$$
\abs{f(t,y_1) - f(t,y_2)} \leq L\abs{y_1 - y_2}
$$
for each $(t,y_1)$,$(t,y_2)$ in $S$.
\end{definition}

\begin{definition}
The \textbf{global truncation error} is defined as $g_i = \abs{w_i-y_i}$, and the \textbf{local truncation error} is defined as $e_{i+1} = \abs{w_{i+1} - z(t_{i+1})}$. $z$ is the correct solution of the one-step IVT starting at $w_i$.
\end{definition}

\begin{theorem}
If $f(t,y)$ has a Lipschitz constant $L$, and the ODE solver has a local truncation error $e_i \leq C h^{k+1}$, then the solver (which is of order $k$) has a global truncation error
$$
g_i = \abs{w_i - y_i} \leq \frac{Ch^k}{L}(e^{L(t_i - a)} - 1)
$$
\end{theorem}

\subsubsection{Taylor Method of order $k$}
\begin{align*}
    w_0 & = y_0 \\
    w_{i+1} & = w_i + h f(t_i, w_i) + \frac{h^2}{2} + ... + \frac{h^k}{k!}f^{(k-1)}(t_i, w_i),
\end{align*}
with a respective error term 
$$
y_{i+1} - w_{i+1}  =  \frac{h^{k+1}}{(k+1)!}y^{(k+11)}(c) = \mathcal{O}(h^{k+1}),
$$
where $c \in [t, t+h]$.

%TODO: Should I add definition of Leipschitz and theorem 6.4 about global error?
\subsubsection{Adaptive methods}
%Idea of adaptive methods in general and Runge-Kutta in particular.
Compare $e_i$ or $e_i/max(\abs{w_i}, \theta)$ with the error tolerance, and change $h_i$ as needed. If $e_i \approx ch_i^{p+1}$, the relative tolerance TOL is satisfied when $\text{TOL} \leq ch^{p+1} / \abs{w_i}$. Solving for $h$ gives the new step size
$$
h_{i+1} = 0.8\left(\frac{\text{TOL}\abs{w_i}}{e_i}\right)^{\frac{1}{p+1}} h_i,
$$
with a safety factor of $0.8$.

The error in going from $t_i$ to $t_{i+1}$ can be estimated as $e_{i+1} \approx \abs{z_{i+1} - w_{i+1}}$, where $z$ is a higher order estimate. This is often done with an \textbf{embedded Runge-Kutta pair} that shares much of the needed computations. An example is the order 2/order 3 embedded pair:

\begin{align*}
w_{i+1} = & w_i + h \frac{s_1 +s_2}{2} \\
z_{i+1} = & w_i + h \frac{s_1 + 4s_3 + s_2}{6}
\end{align*}

where

\begin{align*}
    s_1 = & f(t_i,w_i) \\
    s_2 = & f(t_i + h,w_i + hs_1) \\
    s_3 = & f(t_i + \frac{h}{2},w_i + \frac{h}{2}\frac{s_1 + s_2}{2})
\end{align*}

with an error estimation of

$$
e_{i+1} \approx \abs{w_{i+1} - z_{i+1}} = \abs{h\frac{s_1 - 2s_3 + s_2}{3}}.
$$

You should still use $z_{i+1}$ to advance the step (\textbf{local extrapolation}).