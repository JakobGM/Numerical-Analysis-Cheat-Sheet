\section{ODEs}
% Should I add Leipshitz definiton?
Solving the initial value problem
$$
\begin{cases}
y' = f(t,y) \\
y(a) = y_a \\
t \in [a,b]
\end{cases}
$$
with...
\subsection{Euler's method}
% At the very least, backward/forward Euler.
\begin{align*}
w_0 &= y_0 \\
w_{i+1} &= w_{i} + h f(t_i, w_i)
\end{align*}

\subsection{Backwards Euler Method}
Use this method when the differential equation is \textbf{stiff}, i.e. attracting solutions are surrounded with fast-changing nearby solutions, i.e. when the linear part of $y$ on the r.h.s. is large and negative.
\begin{align*}
w_0 &= y_0 \\
w_{i+1} &= w_{i} + h f(t_{i+1}, w_{i+1})
\end{align*}
Solving this implicit equation for $w_{i+1}$ might require the iterative use of Newton's method.
 
\subsection{Explicit Trapezoid Method}
%Trapezoid method can also be easily stated if you remember the trapezoid quadrature/explicit Euler. 
\begin{align*}
w_0 &= y_0 \\
w_{i+1} &= w_i + \frac{h}{2}(f(t_i,w_i) + f(t_i + h, w_i + hf(t_i,w_i)))
\end{align*}

\subsection{Local and global error}
%Concepts of local/global errors and how local truncation error can be derived for a given method using a Taylor series expansion. 
\begin{definition}
A function $f(t,y)$ is \textbf{Lipschitz continuous} in the variable $y$ on the rectangle $S = [a,b] \times [\alpha, \beta]$ if there exists a constant $L$ (called the \textbf{Lipschitz constant}) satisfying
$$
\abs{f(t,y_1) - f(t,y_2)} \leq L\abs{y_1 - y_2}
$$
for each $(t,y_1)$,$(t,y_2)$ in $S$.
\end{definition}

\begin{definition}
The \textbf{global truncation error} is defined as $g_i = \abs{w_i-y_i}$, and the \textbf{local truncation error} is defined as $e_{i+1} = \abs{w_{i+1} - z(t_{i+1})}$, where $z$ is the correct solution of the one-step IVT with $y_0 = w_i$.
\end{definition}

\begin{theorem}
If $f(t,y)$ has a Lipschitz constant $L$, and the ODE solver has a local truncation error $e_i \leq C h^{k+1}$, then the solver (which is of order $k$) has a global truncation error
$$
g_i = \abs{w_i - y_i} \leq \frac{Ch^k}{L}(e^{L(t_i - a)} - 1).
$$
\end{theorem}

\subsection{Taylor Method of order $k$}
\begin{align*}
    w_0 = \text{ }&y_0 \\
    w_{i+1} = \text{ }&w_i + h f(t_i, w_i) + \frac{h^2}{2} f''(t_i, w_i) \\
    \text{ }&+ ... + \frac{h^k}{k!}f^{(k-1)}(t_i, w_i)
\end{align*}
with the corresponding error term 
$$
y_{i+1} - w_{i+1}  =  \frac{h^{k+1}}{(k+1)!}y^{(k+1)}(c) = \mathcal{O}(h^{k+1}),
$$
where $c \in [t, t+h]$.

%TODO: Should I add definition of Leipschitz and theorem 6.4 about global error?
\subsection{Adaptive methods}
%Idea of adaptive methods in general and Runge-Kutta in particular.
Compare $e_i$ or $e_i/\mcode{max}(\abs{w_i}, \theta)$ with the error tolerance, and change $h_i$ as needed. If $e_i \approx ch_i^{p+1}$, the relative tolerance \mcode{TOL} is satisfied when $\mcode{TOL} \leq ch^{p+1} / \abs{w_i}$. Solving for $h$ gives the new step size
$$
h_{i+1} = 0.8\left(\frac{\mcode{TOL} \cdot \abs{w_i}}{e_i}\right)^{\frac{1}{p+1}} h_i,
$$
with a safety factor of $0.8$.

\subsubsection{Embedded pairs}
The error in going from $t_i$ to $t_{i+1}$ can be estimated as $e_{i+1} \approx \abs{z_{i+1} - w_{i+1}}$, where $z$ is a higher order estimate. This is often done with an \textbf{embedded Runge-Kutta pair} that shares much of the needed computations. An example is the order 2/order 3 embedded pair:

\begin{align*}
w_{i+1} &= w_i + h \frac{s_1 +s_2}{2} \\
z_{i+1} &= w_i + h \frac{s_1 + 4s_3 + s_2}{6}
\end{align*}

where

\begin{align*}
    s_1 &= f(t_i,w_i) \\
    s_2 &= f(t_i + h,w_i + hs_1) \\
    s_3 &= f(t_i + \frac{h}{2},w_i + \frac{h}{2}\frac{s_1 + s_2}{2})
\end{align*}

with an error estimation of

$$
e_{i+1} \approx \abs{w_{i+1} - z_{i+1}} = \abs{h\frac{s_1 - 2s_3 + s_2}{3}}.
$$

It's of course better to use $z_{i+1}$ to advance the step (\textbf{local extrapolation}).

\subsection{Higher order equations}
A single ordinary differential equation of $n$th order,
$$
y^{(n)} = f(t,y,y',y'',...,y^{(n-1)}),
$$
can be converted to a solvable system of $n$ \textit{first order} differential equations by defining new variables $y_i = y^{(i-1)}$ for $i = 1,...,n-1$, and writing the original equation as $y_n' = f(t,y_1,y_2,...,y_n)$. This gives the following system of first-order equations
\begin{align*}
    y_1' &= y_2 \\
    y_2' &= y_3 \\
    y_3' &= y_4 \\
    &\vdots \\
    y_{n-1}' &= y_n \\
    y_n' &= f(t,y_1,...,y_n)
\end{align*}
which can be solved by the methods mentioned earlier in this section.